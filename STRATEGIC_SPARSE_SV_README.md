# Strategic Sparse Supervoxel Labeling - Quick Start

**Date**: 2025-11-10
**Status**: âœ… Implementation complete, tests passing (12/12), bug fixes committed

## What We Built

A complete pipeline for training segmentation models with minimal annotations (0.1% of voxels) using:
1. **Strategic seed sampling** - Max 1 labeled voxel per supervoxel, prioritizing borders and rare classes
2. **Multi-k label propagation** - k-NN propagation for k âˆˆ {1,3,5,7,10,15,20,25,30,50}
3. **Parallel training** - Train all 10 k variants across 2 GPUs

## Key Scripts

- `scripts/sample_strategic_sv_seeds.py` - Strategic seed sampling
- `scripts/propagate_sv_labels_multi_k.py` - Multi-k label propagation
- `scripts/pipeline_strategic_sparse_sv.py` - End-to-end pipeline
- `scripts/train_all_k_variants.sh` - Parallel training script
- `tests/test_strategic_sparse_sv.py` - Comprehensive test suite (12 tests)

## Recent Bug Fixes

### Fix 1: "Processing 0 cases" (Commits: c784aad3, f14ce60e)

**Issue**: Pipeline was loading 0 cases from train split

**Solution**: Updated `load_split_cases()` to:
1. Parse `test_serial_numbers` from split config
2. Search both `data_root/` and `data_root/data/` for image files
3. Extract serial numbers from case IDs (SN13B0_... â†’ 13)
4. Split based on serial number membership

**Result**: Now correctly loads 380 training cases

### Fix 2: "No class 0 (background) in seeds" (Commit: [TBD])

**Issue**: Sampled seeds contained no class 0 (background), only foreground classes

**Root Cause**:
- Per-SV selection scored all voxels together
- FG voxels had 10-20x higher class weights (1.0-2.0 vs 0.1)
- Even in background-dominant SVs, FG voxels always won

**Solution**:
1. Determine each SV's dominant class (via majority vote)
2. Only sample voxels of that dominant class from each SV
3. Use stratified sampling to allocate budget proportionally to GT class frequency
4. Updated class weights to `0.1,1,1,2,2` for classes 0,1,2,3,4

**Result**: Seed distribution now matches GT distribution
- Class 0: ~64% (was 0%)
- Class 1: ~18% (was 1%)
- Class 2: ~12% (was 2%)
- Class 3: ~3% (was 34%)
- Class 4: ~4% (was 63%)

## Commands to Run Experiments

### Complete Pipeline (Recommended) - ONE COMMAND

**Run everything: sampling â†’ propagation â†’ training (12-20 hours)**

```bash
bash scripts/run_strategic_sparse_complete.sh
```

**What it does**:
1. Strategic seed sampling (~1,100 seeds per case, stratified by class)
2. Multi-k label propagation (k=1,3,5,7,10,15,20,25,30,50)
3. Parallel training across 2 GPUs for all 10 k variants
4. Estimated time: ~3h pipeline + ~10-15h training = 12-20h total

**Options**:
```bash
# Custom output directory
bash scripts/run_strategic_sparse_complete.sh --output_dir runs/my_experiment

# Only run pipeline (skip training)
bash scripts/run_strategic_sparse_complete.sh --skip-training

# Only run training (pipeline already done)
bash scripts/run_strategic_sparse_complete.sh --skip-pipeline
```

### Manual Steps (If Needed)

**Step 1: Pipeline Only (Sampling + Propagation)**

```bash
python3 scripts/pipeline_strategic_sparse_sv.py --sv_dir /data3/wp5/monai-sv-sweeps/sv_fullgt_slic_n12000_c0.05_s1.0_ras2_voted --data_root /data3/wp5/wp5-code/dataloaders/wp5-dataset --split_cfg /data3/wp5/wp5-code/dataloaders/wp5-dataset/3ddl_split_config_20250801.json --budget_ratio 0.001 --k_values 1,3,5,7,10,15,20,25,30,50 --output_dir runs/strategic_sparse_0p1pct_k_multi --seed 42
```

**Step 2: Training Only (All K Variants)**

```bash
bash scripts/train_all_k_variants.sh runs/strategic_sparse_0p1pct_k_multi/k_variants
```

**Monitor Training Progress**:
```bash
# Watch GPU 0 jobs
tail -f runs/train_sv_sparse_k01/train.log

# Check completion (should show 10 when done)
ls -d runs/train_sv_sparse_k*/ | wc -l

# See all training runs
ls -d runs/train_sv_sparse_k*/
```

## Output Directory Structure

```
runs/strategic_sparse_0p1pct_k_multi/
â”œâ”€â”€ strategic_seeds/              # Seed sampling outputs
â”‚   â”œâ”€â”€ SN13B0_..._strategic_seeds.npy
â”‚   â”œâ”€â”€ SN13B0_..._sv_labels_sparse.json
â”‚   â”œâ”€â”€ SN13B0_..._seeds_meta.json
â”‚   â””â”€â”€ summary_stats.json
â”œâ”€â”€ cases/                         # Propagation outputs
â”‚   â””â”€â”€ SN13B0_I17_3D_B1_1B250409/
â”‚       â”œâ”€â”€ sparse_sv_labels.json
â”‚       â”œâ”€â”€ propagated_k01_labels.npy
â”‚       â”œâ”€â”€ propagated_k03_labels.npy
â”‚       â”œâ”€â”€ ... (k=5,7,10,15,20,25,30,50)
â”‚       â””â”€â”€ propagation_meta.json
â”œâ”€â”€ k_variants/                    # Training directories (symlinks)
â”‚   â”œâ”€â”€ k01/ ... k50/
â”‚   â”‚   â””â”€â”€ SN13B0_..._labels.npy -> ../../cases/.../propagated_k*_labels.npy
â””â”€â”€ propagation_summary.json

runs/train_sv_sparse_k01/          # Training outputs
    â”œâ”€â”€ best.ckpt
    â”œâ”€â”€ last.ckpt
    â”œâ”€â”€ train.log
    â””â”€â”€ metrics/
runs/train_sv_sparse_k03/
...
runs/train_sv_sparse_k50/
```

## Testing

Run comprehensive tests:
```bash
pytest tests/test_strategic_sparse_sv.py -v
```

**Test coverage** (12 tests, all passing):
- Strategic sampling: max 1 per SV, budget, FG priority, rare class priority, gradient detection
- Multi-k propagation: all k values, sparse preservation, voting, distance weighting
- Helper functions: centroids, gradients, SV-to-dense conversion

## Expected Performance

| Method | Training Labels | Test Dice (Expected) | % of 100% GT |
|--------|----------------|----------------------|--------------|
| 100% GT | 380 dense labels | 0.8718 | 100% |
| 12k SV full GT | 380 SV-voted | 0.9089 | 104.3% |
| 1% sparse points | ~1,100 points Ã— 380 | 0.8310 | 95.3% |
| **0.1% â†’ SV prop (k=5)** | **~1,100 points Ã— 380** | **~0.78-0.82 (?)** | **~90-94% (?)** |

**Hypothesis**: Optimal k should be 5-10 (balances locality vs robustness)

## Verification

Verify the dataset is loaded correctly:
```bash
python3 -c "import os; from pathlib import Path; print(f'Total cases: {len([n for n in os.listdir(Path(\"/data3/wp5/wp5-code/dataloaders/wp5-dataset/data\")) if n.endswith(\"_image.nii\")])}')"
```

Expected: `Total cases: 560` (380 train + 180 test)

## Next Steps

1. âœ… Run end-to-end pipeline (command #1 above)
2. âœ… Verify outputs in `runs/strategic_sparse_0p1pct_k_multi/`
3. ðŸ”„ Train all k variants (command #2 above)
4. ðŸ“Š Compare results across k values
5. ðŸ“ˆ Identify optimal k for sparse supervoxel labeling

## Documentation

Full documentation in `AGENTS.md` section: "Strategic Sparse Supervoxel Labeling (0.1% Budget)"

## Git History

```bash
# View recent commits
git log --oneline -10

# Key commits:
# 91e7666d docs: update strategic sparse SV pipeline commands and troubleshooting
# f14ce60e fix: handle data/ subdirectory in split loading and file paths
# c784aad3 fix: correct split config parsing in strategic sampling script
# 87ef6b45 feat: add end-to-end pipeline for strategic sparse SV labeling
# 4c3ed8e8 feat: add multi-k label propagation script
# 51229ebe feat: add strategic sparse SV seed sampling script
# a1b08f42 test: add comprehensive tests for strategic sparse SV pipeline
```
