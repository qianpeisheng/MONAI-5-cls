Sure â€” hereâ€™s a single, self-contained `README.md` file that your coding agent can follow to implement everything exactly as described:

---

```markdown
# Sparse2Dense Polygon-Like 3D Label Generator

This project converts **dense 3D medical segmentation labels** into **pseudo-dense masks** reconstructed from only **1% of labeled voxels**.
It is tailored for polygon-like, inclusive/disjoint structures (e.g., organs or semiconductor features).

---

## ğŸ”§ Key Features
- Uses only **1% of voxels** (boundary â‰ˆ 70%, interior â‰ˆ 20%, guards â‰ˆ 10%).
- Smart voxel selection via:
  - Boundary curvature & farthest-point sampling
  - Interior Poisson-disk anchors
  - Guard points along surface normals
- Reconstruction by **RBF-based Signed-Distance Fields (SDF)** + optional 3D Dense CRF.
- Preserves original `.nii` filenames and affines.
- Saves full **intermediates** (selected points, masks, SDFs, metrics).
- Works directly with **MONAI datalist JSONs** for train/test splits.

---

## ğŸ—‚ï¸ Project Structure
```

sparse2dense_poly3d/
â”œâ”€â”€ **init**.py
â”œâ”€â”€ io_utils.py
â”œâ”€â”€ geom_utils.py
â”œâ”€â”€ sampler.py
â”œâ”€â”€ reconstruct.py
â”œâ”€â”€ run_sparse2dense.py
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md

```

### Dependencies
```

numpy
scipy
scikit-image
nibabel
tqdm
scikit-learn
pyyaml
pydensecrf   # optional (for CRF refinement)

````

---

## âš™ï¸ Data Paths

| Item | Path |
|------|------|
| Dataset root | `/data3/wp5/wp5-code/dataloaders/wp5-dataset/data` |
| Train list (MONAI JSON) | `/home/peisheng/MONAI/datalist_train.json` |
| Test list (unused) | `/home/peisheng/MONAI/datalist_test.json` |
| Output pseudo-labels | `/data3/wp5/wp5-code/dataloaders/wp5-dataset/pseudo_labels_1pct_train` |
| Intermediates | `/data3/wp5/wp5-code/dataloaders/wp5-dataset/pseudo_labels_1pct_train_intermediate` |

Each entry in the train list contains `"image"` and `"label"` fields (absolute or relative to the dataset root).

---

## ğŸš€ CLI Usage

```bash
pip install -e .

python -m sparse2dense_poly3d.run_sparse2dense \
  --dataset_root /data3/wp5/wp5-code/dataloaders/wp5-dataset/data \
  --train_list /home/peisheng/MONAI/datalist_train.json \
  --out_pseudolabels_dir /data3/wp5/wp5-code/dataloaders/wp5-dataset/pseudo_labels_1pct_train \
  --out_intermediates_dir /data3/wp5/wp5-code/dataloaders/wp5-dataset/pseudo_labels_1pct_train_intermediate \
  --budget_ratio 0.01 \
  --boundary_ratio 0.7 --interior_ratio 0.2 --guard_ratio 0.1 \
  --rbf_kernel multiquadric --rbf_eps 2.0 --margin_vox 1.5 \
  --crf False \
  --spacing_from_header True
````

This processes **only training cases**, generates pseudo-dense labels, and logs Dice + HD95 against the ground truth.

---

## ğŸ“ Outputs

Each case gets a mirrored folder under `pseudo_labels_1pct_train/`:

* **Pseudo label** â€” identical name/extension (`.nii`), affine, dtype.
* **Sidecar JSON** `<case>.json`:

  ```json
  {
    "selected_points_counts": {"boundary": N, "interior": M, "guard_in": A, "guard_out": B},
    "selected_mask_relpath": "REL/path/to/mask_selected_points.nii",
    "budget_ratio": 0.01,
    "source_label_relpath": "REL/path/to/original/label.nii"
  }
  ```

Intermediates saved under
`pseudo_labels_1pct_train_intermediate/<case_id>/`:

```
selected_points.npz
mask_selected_points.nii
boundary_voxels_class<k>.nii
surface_samples_class<k>.npz
sdf_coeffs_class<k>.npz
sdf_volume_class<k>.nii
(optional) mask_after_crf.nii
summary.yaml
```

A global `dataset_summary.csv` aggregates per-case metrics.

---

## ğŸ§© Module Responsibilities

### `io_utils.py`

* Load/save NIfTI (`.nii`)
* Parse MONAI datalist
* Mirror paths
* Extract voxel spacing
* JSON I/O helpers

### `geom_utils.py`

* Compute class boundaries
* Surface area via marching cubes
* Farthest-point sampling
* Normal estimation (PCA)
* Poisson-disk interior sampling
* Normal-offset guard points

### `sampler.py`

Implements `select_points_1pct()`:

1. Allocate budget per class (by surface area).
2. Pick boundary / interior / guard points.
3. Build integer mask of selected voxels (0â€“4 codes).
4. Return `points_dict` + mask.

### `reconstruct.py`

Implements `reconstruct_from_points()`:

1. Fit RBF SDF for each class.
2. Optionally enforce inclusion/disjoint constraints.
3. Rasterize with marching cubes â†’ voxel mask.
4. Optional Dense CRF refine.
5. Return reconstructed pseudo mask.

### `run_sparse2dense.py`

Main entrypoint:

1. Read datalist â†’ label paths.
2. Load GT, spacing.
3. Run sampler â†’ save intermediates.
4. Run reconstruction â†’ save pseudo label.
5. Save sidecar JSON & metrics.

---

## ğŸ“Š Typical Performance (Easy Tasks)

| Setting              | Macro-Dice vs GT | HD95 vs GT     |
| -------------------- | ---------------- | -------------- |
| Random 1%            | 0.72 â€“ 0.85Ã—     | 1.5â€“2.5Ã—       |
| Smart 1% (this repo) | **0.92 â€“ 0.98Ã—** | **â‰ˆ 1.0â€“1.3Ã—** |
| Full supervision     | 1.00             | 1.00           |

---

## ğŸ’¡ Training Integration

Just point your training config to:

```
/data3/wp5/wp5-code/dataloaders/wp5-dataset/pseudo_labels_1pct_train/
```

All file names and shapes remain identical to the originals, so no change in code logic is required.

---

## ğŸ§ª Optional Test (Synthetic Sanity Check)

Create `tests/test_synthetic.py`:

* Generate small cubes/spheres â†’ save `.nii`
* Run CLI with `--budget_ratio=0.01`
* Assert Dice â‰¥ 0.95 for large shapes

---

## âœ… Implementation Notes

* Evaluate SDFs in 64Â³ tiles if RAM limited.
* If `pydensecrf` unavailable, skip CRF gracefully.
* For highly polygonal data, raise `--boundary_ratio` to 0.8 â€“ 0.85.
* Extend later with a `--method rw` flag for Random-Walker reconstruction.

---

## ğŸ“Œ Summary

After running:

```
pseudo_labels_1pct_train/
â”œâ”€â”€ case001_label.nii
â”œâ”€â”€ case001_label.json
â”œâ”€â”€ ...
```

you can train with these labels as if they were dense.
Use `mask_selected_points.nii` or the JSON sidecar to visualize where the 1% points lie.

---

Got it. Here are the **updated, copy-paste prompts** tailored to your paths and split files:

* Data root: `/data3/wp5/wp5-code/dataloaders/wp5-dataset/data`
* Train list: `/home/peisheng/MONAI/datalist_train.json`
* Test list: `/home/peisheng/MONAI/datalist_test.json`
* Labels/images are **`.nii`** (not `.nii.gz`)
* We will process **train set only** and mirror filenames/format into a new folder.

---

# Prompt 1 â€” Project scaffold (paths + CLI)

> Create a Python CLI project `sparse2dense_poly3d/` with:
>
> * `sparse2dense_poly3d/__init__.py`
> * `sparse2dense_poly3d/io_utils.py`
> * `sparse2dense_poly3d/geom_utils.py`
> * `sparse2dense_poly3d/sampler.py`
> * `sparse2dense_poly3d/reconstruct.py`
> * `sparse2dense_poly3d/run_sparse2dense.py`
> * `pyproject.toml` deps: `numpy`, `scipy`, `scikit-image`, `nibabel`, `tqdm`, `scikit-learn`, `pydensecrf` (optional, guard), `pyyaml`
> * `README.md`
>
> **CLI (train set only):**
>
> ```bash
> python -m sparse2dense_poly3d.run_sparse2dense \
>   --dataset_root /data3/wp5/wp5-code/dataloaders/wp5-dataset/data \
>   --train_list /home/peisheng/MONAI/datalist_train.json \
>   --out_pseudolabels_dir /data3/wp5/wp5-code/dataloaders/wp5-dataset/pseudo_labels_1pct_train \
>   --out_intermediates_dir /data3/wp5/wp5-code/dataloaders/wp5-dataset/pseudo_labels_1pct_train_intermediate \
>   --budget_ratio 0.01 \
>   --boundary_ratio 0.7 --interior_ratio 0.2 --guard_ratio 0.1 \
>   --rbf_kernel multiquadric --rbf_eps 2.0 --margin_vox 1.5 \
>   --crf False \
>   --spacing_from_header True
> ```
>
> **Requirements & behavior:**
>
> * Read **only training cases** from `--train_list` (ignore `--test_list` entirely).
> * The datalist JSON follows MONAI style (per-item dicts with `"image"` and `"label"`). Paths may be **absolute or relative** to `--dataset_root`; resolve both.
> * For every train case, load the **label `.nii`** file and produce a **pseudo-dense label** `.nii` with the **identical filename** (same stem and extension) under `--out_pseudolabels_dir`, preserving affine + dtype.
> * Save **intermediates** under `--out_intermediates_dir/<case_id>/`:
>
>   * `selected_points.npz` (keys per class: `coords_boundary`, `coords_interior`, `coords_guards_in`, `coords_guards_out`)
>   * `mask_selected_points.nii` (int codes: 0=unlabeled, 1=boundary, 2=interior, 3=guard_in, 4=guard_out)
>   * `boundary_voxels_class<k>.nii`
>   * `surface_samples_class<k>.npz` (ijk and physical mm coords if spacing available)
>   * `sdf_coeffs_class<k>.npz` and `sdf_volume_class<k>.nii`
>   * If `--crf True`, also save `crf_probs.nii` and `mask_after_crf.nii`
> * Next to each pseudo label, write a **JSON sidecar** (same stem, `.json`) containing:
>
>   ```json
>   {
>     "selected_points_counts": {"boundary": N, "interior": M, "guard_in": A, "guard_out": B},
>     "selected_mask_relpath": "REL/path/to/mask_selected_points.nii",
>     "budget_ratio": 0.01,
>     "source_label_relpath": "REL/path/to/original/label.nii"
>   }
>   ```
> * Log per-case metrics vs GT (Dice per class + HD95), and write a `dataset_summary.csv` after all cases.

---

# Prompt 2 â€” I/O utilities (NIfTI `.nii`, datalist support)

> In `io_utils.py`, implement:
>
> * `read_datalist(list_path: Path) -> List[Dict]`: load JSON; return list of dicts with keys like `"image"`, `"label"`.
> * `resolve_path(p: str, dataset_root: Path) -> Path`: if `p` is absolute and exists, return; else return `dataset_root / p`.
> * `iter_train_label_paths(train_list_path, dataset_root) -> List[Path]`: for each item, resolve `"label"` to an existing `.nii` path; raise if not found.
> * `mirror_path(src_path: Path, src_root: Path, dst_root: Path) -> Path`: recreate relative subdirs & filename under `dst_root`. Keep **`.nii`** extension.
> * `load_nifti(path) -> (np.ndarray, affine, header)` using `nibabel`.
> * `save_nifti(arr, affine, header, path)`: ensure parent dirs; copy dtype from `header.get_data_dtype()`; keep `.nii`.
> * `get_spacing_mm(header) -> Tuple[float,float,float]` from pixdim (fallback `(1,1,1)`).
> * `save_json(obj, path)` and `load_json(path)`.

---

# Prompt 3 â€” Geometry helpers

> In `geom_utils.py`, add:
>
> 1. `compute_class_boundary(mask, k) -> np.ndarray[bool]` using 6-conn erosion XOR original (class k only).
> 2. `surface_area_vox(mask_k, spacing) -> float`: marching cubes on `mask_k` then sum triangle areas.
> 3. `fps_boundary(coords_mm: (N,3), target_n: int) -> np.ndarray[int]`: farthest-point sampling in **mm** space (greedy).
> 4. `estimate_normals(mask_k, boundary_coords_ijk, spacing, radius_vox=2) -> np.ndarray[(B,3)]` via local PCA on neighborhood points; orient inward by checking a step along normal stays in class.
> 5. `poisson_disk_interior(mask_k, spacing, min_dist_mm) -> np.ndarray[(M,3)]` using grid hashing; avoid voxels within ~1 voxel of boundary.
> 6. `step_along_normal(coord_ijk, normal_unit_mm, spacing, d_vox) -> (inside_ijk, outside_ijk)`; clamp to bounds.

---

# Prompt 4 â€” 1% selector

> In `sampler.py`, implement `select_points_1pct(mask, spacing, budget_ratio=0.01, boundary_ratio=0.7, interior_ratio=0.2, guard_ratio=0.1, margin_vox=1.5)`:
>
> * Inputs: `mask` `(Z,Y,X)` with labels `{0..K}`, spacing in mm.
> * Compute **total budget** `M = floor(budget_ratio * Z*Y*X)`.
> * For each **foreground** class `k=1..K`:
>
>   * `mask_k = (mask==k)`, `boundary_k = compute_class_boundary(mask, k)`.
>   * **Per-class share** proportional to **surface area** `surface_area_vox(mask_k, spacing)`, with a floor so each fg class gets â‰¥ `max(64, 0.01 * M / K)` points.
>   * Choose `nb = round(share * boundary_ratio)`, `ni = round(share * interior_ratio)`, `ng = round(share * guard_ratio)`.
>   * Boundary coords â†’ mm â†’ `fps_boundary` â†’ take `nb`.
>   * Normals at selected boundary; for as many as `ng`, emit **inside/outside** guard points at Â±`margin_vox` steps.
>   * Interior anchors: `poisson_disk_interior` until `ni`.
> * **Background guards** are the outside guard points (label 0).
> * Build `mask_selected_points` with codes {0,1,2,3,4}.
> * **Trim** if total selected > `M` (proportionally per category), and return:
>
>   * `points_dict`: dict per class with `boundary`, `interior`, `guard_in`, `guard_out` (all in **ijk** integer coords).
>   * `mask_selected_points`.

---

# Prompt 5 â€” Reconstruction (RBF-SDF; `.nii` everywhere)

> In `reconstruct.py`, implement `reconstruct_from_points(mask_gt, points_dict, spacing, rbf_kernel="multiquadric", rbf_eps=2.0, margin_vox=1.5, use_crf=False, image=None, nesting=None)`:
>
> * For each fg class `k`:
>
>   * Build constraints (in **mm** coords): boundary points with `phi=0`; interior with `phi<=-m`; outside guards with `phi>=+m`, where `m = margin_vox * mean(spacing)`.
>   * Fit `phi_k` with `scipy.interpolate.Rbf(x,y,z, t, function=rbf_kernel, epsilon=rbf_eps, smooth=Î»)` with small Î» (e.g., 1e-3).
>   * Evaluate `phi_k` grid-wise in tiles to control RAM; save `sdf_volume_class<k>.nii`.
> * **Inclusion (optional `nesting`)**: if provided as parentâ†’children dict, clamp child `phi_child = np.minimum(phi_child, phi_parent - Î´)`.
> * Convert to logits: `logit_k = -phi_k`; background logit = 0.
> * Assign labels by `argmax` over {background, classes}; produce `mask_pred`.
> * If `use_crf` and `image` is not None: run light 3D DenseCRF (contrast-sensitive); save `mask_after_crf.nii` and probs.
> * Return `mask_pred` and per-class SDFs.

---

# Prompt 6 â€” Runner (reads MONAI train list, mirrors filenames)

> In `run_sparse2dense.py`:
>
> * Parse args:
>
>   * `--dataset_root`, `--train_list`, `--out_pseudolabels_dir`, `--out_intermediates_dir`
>   * `--budget_ratio`, `--boundary_ratio`, `--interior_ratio`, `--guard_ratio`, `--margin_vox`
>   * `--rbf_kernel`, `--rbf_eps`, `--crf`, `--spacing_from_header`
> * For each train item:
>
>   1. Resolve **label path** via `resolve_path(item["label"], dataset_root)`; ensure suffix is `.nii`.
>   2. (Optional) Resolve **image path** if exists (same logic); pass to CRF if `--crf True`.
>   3. Load `label_gt` (array, affine, header); `spacing = get_spacing_mm(header)` if `--spacing_from_header True` else `(1,1,1)`.
>   4. Run `select_points_1pct(...)` â†’ `points_dict`, `mask_selected_points`.
>   5. Save intermediates in `<out_intermediates_dir>/<case_id>/`:
>
>      * `selected_points.npz`, `mask_selected_points.nii`, `boundary_voxels_class<k>.nii`, `surface_samples_class<k>.npz`.
>   6. Run `reconstruct_from_points(...)` â†’ `pseudo_mask`; save to **mirrored** path under `--out_pseudolabels_dir` (same filename `.nii`).
>   7. Write **sidecar JSON** next to pseudo label as specified (counts, relpaths).
>   8. Compute metrics vs GT (Dice per class, HD95) and write `<case_id>/summary.yaml`.
> * After loop, aggregate to `dataset_summary.csv` in `--out_pseudolabels_dir`.
> * Print a short completion summary (cases processed, mean macro-Dice, output dirs).

---

# Prompt 7 â€” README usage (with your real paths)

> Update `README.md` with:
>
> ```bash
> pip install -e .
>
> # Train-set only conversion to pseudo-dense labels (1% of voxels kept)
> python -m sparse2dense_poly3d.run_sparse2dense \
>   --dataset_root /data3/wp5/wp5-code/dataloaders/wp5-dataset/data \
>   --train_list /home/peisheng/MONAI/datalist_train.json \
>   --out_pseudolabels_dir /data3/wp5/wp5-code/dataloaders/wp5-dataset/pseudo_labels_1pct_train \
>   --out_intermediates_dir /data3/wp5/wp5-code/dataloaders/wp5-dataset/pseudo_labels_1pct_train_intermediate \
>   --budget_ratio 0.01 \
>   --boundary_ratio 0.7 --interior_ratio 0.2 --guard_ratio 0.1 \
>   --rbf_kernel multiquadric --rbf_eps 2.0 --margin_vox 1.5 \
>   --crf False \
>   --spacing_from_header True
>
> # Your training code should load labels from:
> #   /data3/.../pseudo_labels_1pct_train/
> # The filenames and `.nii` format are identical to the originals.
> # If you need to know which voxels were actually labeled, read the
> # sidecar JSON or the mask_selected_points.nii in the intermediates.
> ```
>
> Add a note that **test set is untouched**; we only transform the train labels.

---

### Notes / gotchas

* If the MONAI datalist stores labels under another key (e.g., `"label"` vs `"labels"`), support both.
* If memory is tight, evaluate RBF SDFs in tiles (e.g., `64Â³` chunks) and optionally cap neighbors per tile via KD-tree.
* If you later want **Random Walker** instead of RBF-SDF, add a `--method rw` switch and use seeds from the same `points_dict`.

These prompts should give you a turn-key pipeline that **uses exactly ~1% of voxels**, saves all the **intermediates**, and writes pseudo-dense labels with **the same `.nii` filenames** into a new folder for drop-in training.
